{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56ed63b-ff21-49ee-bb73-5da31df46d03",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this week’s discussion section, we will use simulated datasets to create a widget that looks at the results of a Support Vector Machine. The simulated datasents represent different relationships within our data. Our widget will allow us to select different kernels, regularization parameters, and methods for calculating gamma, allowing us to see how these changes change the classification of our data. The image below serves as a reminder of a few of the different kernels we can use in a Support Vector Machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d72ae55-815c-433e-b19c-bf3ffa0000d0",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As mentioned above, the data we will be working with this week is all simulated. Copy the code cell below to obtain the data.\n",
    "\n",
    "## Excercise\n",
    "\n",
    "### Load in libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9c51a7-ab2f-4964-ba04-ecc4e45f4e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe5e5df-2cf3-4002-ac1a-f60b1730f9d6",
   "metadata": {},
   "source": [
    "### Create simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae344ac-7de9-4536-bbad-9c1fc937c05f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate Linearly Separable Data\n",
    "X1 = np.random.randn(100, 2) + [2, 2]\n",
    "X2 = np.random.randn(100, 2) + [5, 5]\n",
    "X_linear = np.vstack((X1, X2))\n",
    "y_linear = np.array([0]*100 + [1]*100)\n",
    "df_linear = pd.DataFrame(X_linear, columns=['Temperature', 'Humidity'])\n",
    "df_linear['Pollution_Level'] = y_linear\n",
    "\n",
    "# Generate Non-linearly Separable Data (Circular Boundaries)\n",
    "length = 200\n",
    "radius = 2\n",
    "angle = np.linspace(0, 2 * np.pi, length)\n",
    "X1_circular = np.vstack((np.sin(angle) * radius, np.cos(angle) * radius)).T + np.random.randn(length, 2) * 0.1\n",
    "X2_circular = np.random.randn(length, 2) * 0.5\n",
    "X_circular = np.vstack((X1_circular, X2_circular))\n",
    "y_circular = np.array([0] * length + [1] * length)\n",
    "df_circular = pd.DataFrame(X_circular, columns=['CO2_Emission', 'Water_Usage'])\n",
    "df_circular['Area_Type'] = y_circular\n",
    "\n",
    "# Generate XOR-like Data\n",
    "X1_xor = np.random.randn(50, 2) + [2, 2]\n",
    "X2_xor = np.random.randn(50, 2) + [2, 5]\n",
    "X3_xor = np.random.randn(50, 2) + [5, 2]\n",
    "X4_xor = np.random.randn(50, 2) + [5, 5]\n",
    "X_xor = np.vstack((X1_xor, X2_xor, X3_xor, X4_xor))\n",
    "y_xor = np.array([0]*100 + [1]*100)\n",
    "df_xor = pd.DataFrame(X_xor, columns=['Species_Count', 'Toxicity_Level'])\n",
    "df_xor['Habitat_Damage'] = y_xor\n",
    "\n",
    "# Generate Overlapping Data\n",
    "X1_overlap = np.random.randn(100, 2) + [3, 3]\n",
    "X2_overlap = np.random.randn(100, 2) + [4, 4]\n",
    "X_overlap = np.vstack((X1_overlap, X2_overlap))\n",
    "y_overlap = np.array([0]*100 + [1]*100)\n",
    "df_overlap = pd.DataFrame(X_overlap, columns=['Air_Quality', 'Noise_Level'])\n",
    "df_overlap['Health_Risk'] = y_overlap\n",
    "\n",
    "# Collect all datasets in a dictionary for easy access\n",
    "datasets = {\n",
    "    'linear_data': df_linear,\n",
    "    'circular_data': df_circular,\n",
    "    'xor_data': df_xor,\n",
    "    'overlapping_data': df_overlap\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa6c05-abac-43bb-940f-df9d9405851d",
   "metadata": {},
   "source": [
    "### Create a SVM Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ccd0c1-6a7e-421e-9f04-3a0e336eaca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee93156b3dbb4f80b6493549f913e57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Kernel:', options=('linear', 'rbf', 'poly'), value='linear'), Floa…"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def interactive_svm(kernel, C, gamma, data_key):\n",
    "    \n",
    "    # Seperate features and target\n",
    "    data = datasets[data_key]\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "    \n",
    "    feature_names = X.columns\n",
    "    target_name = data.columns[-1]\n",
    "    \n",
    "    \n",
    "    # Preprocess data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3, random_state = 42)\n",
    "    \n",
    "    # Train the SVM model and predict\n",
    "    model = SVC(kernel = kernel,\n",
    "                C = C,\n",
    "                gamma = gamma)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Plot the decisions boundaries\n",
    "    \n",
    "    if X.shape[1] == 2:\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize = (10,6))\n",
    "        \n",
    "        # Create the mesh for decision boundary\n",
    "        \n",
    "        # Get min and max for x1 and x2 and extend by a unit\n",
    "        \n",
    "        x1_min, x1_max = X_test.iloc[:, 0].min() - 1, X_test.iloc[:, 0].max() + 1\n",
    "        x2_min, x2_max = X_test.iloc[:, 1].min() -1, X_test.iloc[:, 1].max() + 1\n",
    "        \n",
    "        xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max, 100),\n",
    "                              np.linspace(x2_min, x2_max, 100))\n",
    "        \n",
    "        # predict for the mesh grid\n",
    "        y_pred_input = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "        y_pred_input_df = pd.DataFrame(y_pred_input, columns = feature_names[:2])\n",
    "        y_pred = model.predict(y_pred_input_df)\n",
    "        y_pred = y_pred.reshape(xx1.shape)\n",
    "        \n",
    "        # Report accuracies\n",
    "        print(\"Accuracy Score\\n\")\n",
    "        print(accuracy_score(y_test, predictions))\n",
    "        \n",
    "        # Plot desicion boundary using a filled contour plot\n",
    "        plt.contourf(xx1, xx2, y_pred, alpha = 0.4, cmap = plt.cm.RdYlBu)\n",
    "        \n",
    "        scatter = plt.scatter(X_scaled.iloc[:,0], X_scaled.iloc[:,1], c = y, cmap = plt.cm.RdYlBu)\n",
    "        \n",
    "        # Define the colors used in scatterplot\n",
    "        colors = [plt.cm.RdYlBu(i) for i in np.linspace(0,1, len(np.unique(y)))]\n",
    "        \n",
    "        legend_handles = [Line2D([0], [0], \n",
    "                                 marker = 'o', \n",
    "                                 color = 'w', \n",
    "                                 label = f'{label}',\n",
    "                                 markerfacecolor = color, \n",
    "                                 markersize = 10, \n",
    "                                 linestyle = 'none') for color, label in zip(colors, np.unique(y))]\n",
    "        \n",
    "        # Add the custom legend to the plot\n",
    "        ax.legend(handles = legend_handles, \n",
    "                  loc = 'upper right', \n",
    "                  title = f'{target_name}')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel(X.columns[0])\n",
    "        plt.ylabel(X.columns[1])\n",
    "        plt.title(f'SVM Decision Boundary (Kernel: {kernel})')\n",
    "        plt.show()\n",
    "        \n",
    "    return model\n",
    "\n",
    "# kernel selector\n",
    "kernel_widget = widgets.Dropdown(\n",
    "    value = 'linear',\n",
    "    options = ['linear', 'rbf', 'poly'],\n",
    "    description = 'Kernel:'\n",
    ")\n",
    "\n",
    "# regularization parameter selector\n",
    "c_widget = widgets.FloatLogSlider(\n",
    "    value = 1,\n",
    "    base = 10,\n",
    "    min = -3,\n",
    "    max = 3,\n",
    "    description = 'C (Regularization Parameter):'\n",
    ")\n",
    "\n",
    "# gamma selector\n",
    "gamma_widget = widgets.Dropdown(\n",
    "    options = ['scale', 'auto'],\n",
    "    value = 'scale',\n",
    "    description = 'Gamma:'\n",
    ")\n",
    "\n",
    "# dataset widget\n",
    "dataset_widget = widgets.Dropdown(\n",
    "    options = list(datasets.keys()),\n",
    "    value = 'linear_data',\n",
    "    description = 'Dataset:'\n",
    ")\n",
    "\n",
    "widgets.interactive(\n",
    "    interactive_svm,\n",
    "    C = c_widget,\n",
    "    gamma = gamma_widget,\n",
    "    kernel = kernel_widget,\n",
    "    data_key = dataset_widget\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda 3 (EDS232)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
